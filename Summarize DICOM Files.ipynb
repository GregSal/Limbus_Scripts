{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize DICOM Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "import pydicom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(r'C:\\DICOM EXPORT\\For Limbus')\n",
    "working_dir = base_dir / 'Anonymized'\n",
    "cleaned_dir = base_dir / 'Cleaned'\n",
    "\n",
    "top_dir = str(cleaned_dir)\n",
    "save_file = Path.cwd() / 'DICOM References.xlsx'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a relative path string from two paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_relative_path(file_path: Path, top_dir: Path)->str:\n",
    "    '''Build a relative path string (starts with \"./\") to the given file.\n",
    "\n",
    "    The top_dir path is removed from file_path and replaced with \"./\" \n",
    "\n",
    "    Args:\n",
    "        file_path (Path): The full path to the file.\n",
    "        top_dir (Path): The path to a higher level folder containing file_path.\n",
    "    Returns:\n",
    "        str: String representing the relative path from top_dir to file_path.  \n",
    "            If file_path is not in top_dir, or a sub-directory of top_dir, the \n",
    "            full path is returned.\n",
    "    '''\n",
    "    top_dir_name = str(top_dir)\n",
    "    path_str = str(file_path)\n",
    "    relative_path_str = path_str.replace(top_dir_name, r'.')\n",
    "    return relative_path_str\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a list to a string for displaying in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(structure_list: List[str])->str:\n",
    "    '''Convert a list of strings to a string representation.\n",
    "    \n",
    "    This is meant to work like the __repr__() function for a list of strings, \n",
    "    but it needs to be applied to a Pandas.DataFrame column.\n",
    "\n",
    "    Args:\n",
    "        structure_list (List[str]): List of structure names\n",
    "\n",
    "    Returns:\n",
    "        str: string representation of the list.\n",
    "    '''\n",
    "    structure_str = '['\n",
    "    for structure in structure_list:\n",
    "        structure_str = structure_str + str(structure) + ', '\n",
    "    if len(structure_str) > 1:\n",
    "        structure_str = structure_str[0:-2] + ']'\n",
    "    else:\n",
    "        structure_str = structure_str + ']'\n",
    "    return structure_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(date_str: str)->date:\n",
    "    '''Convert a date string for a date object.\n",
    "\n",
    "    Date string is assumed to have the form: yyymmdd.\n",
    "\n",
    "    Args:\n",
    "        date_str (str): Date string in the format yyymmdd.\n",
    "\n",
    "    Returns:\n",
    "        date: A corresponding python date object.\n",
    "    '''\n",
    "    year = int(date_str[:4])\n",
    "    month = int(date_str[4:6])\n",
    "    day = int(date_str[6:])\n",
    "    return date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_date(date_val: date)->str:\n",
    "    '''Convert a date object to a string with the form: yyymmdd.\n",
    "\n",
    "    Args:\n",
    "        date_val (date): A python date object.\n",
    "\n",
    "    Returns:\n",
    "        str: The corresponding string in the form: yyymmdd.\n",
    "    '''\n",
    "    date_str = f'{date_val.year:04d}{date_val.month:02d}{date_val.day:02d}'\n",
    "    return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_shift(date_str: str, date_offset: date, \n",
    "               ref_date=date(2000, 1, 1))->str:\n",
    "    '''Shift the supplied date\n",
    "\n",
    "     Shift the date such that the the difference between the new date and the \n",
    "     reference date is the same a the difference between the original date and \n",
    "     the date offset,\n",
    "\n",
    "    Args:\n",
    "        date_str (str): Date string in the format yyymmdd.\n",
    "        date_offset (date): A reference date for date_str.\n",
    "        ref_date (date, optional): The new reference date. \n",
    "            Defaults to date(2000, 1, 1).\n",
    "\n",
    "    Returns:\n",
    "        str: The adjusted date string in the format yyymmdd.\n",
    "    '''\n",
    "    date_dif = to_date(date_str) - date_offset\n",
    "    new_date = ref_date + date_dif\n",
    "    new_date_str = from_date(new_date)\n",
    "    return new_date_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicator code\n",
    "Code indicates what applicator is used.\n",
    "\n",
    "Code is built from private DICOM tags in the Oncentra plan.\n",
    "\n",
    "**Code Format**<br>\n",
    "> `RT_A`##`R`##`T`##\n",
    "\n",
    "- **RT**: Ring & Tandem\n",
    "- **A**: Angle of tandem in degrees\n",
    "- **R**: Diameter of ring in mm\n",
    "- **T**: Length of tandem in mm\n",
    "\n",
    "Example: `RT_A60R30T40`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_appl_code(dataset: pydicom.Dataset)->Dict[str, str]:\n",
    "    '''Construct an applicator code for a given RT-DICOM Plan Dataset.\n",
    "    \n",
    "    If successful the returning dictionary will contain the following items:\n",
    "    Ring: Ring diameter in mm.\n",
    "    Tandem: Tandem length in mm.\n",
    "    Angle: Tandem angle from ring in degrees.\n",
    "    Applicator: Applicator Code (as described below)\n",
    "\n",
    "    The Code Format is: RT_A##R##T##\n",
    "    Where:\n",
    "        - RT: Ring & Tandem\n",
    "        - A: Angle of tandem in degrees\n",
    "        - R: Diameter of ring in mm\n",
    "        - T: length of tandem in mm\n",
    "    Example: RT_A60R30T40\n",
    "    \n",
    "    If applicator information is present, but not in the expected format, the\n",
    "    applicator string is returned as the only item in the dictionary.\n",
    "    \n",
    "    If applicator information is not present an empty dictionary is returned.\n",
    "\n",
    "    Args:\n",
    "        dataset (pydicom.Dataset): RT-DICOM Plan Dataset\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: Applicator parameters and Code String or empty string if applicator \n",
    "             information was not found.\n",
    "    '''\n",
    "    appl_ptrn = re.compile(\n",
    "        r'.*?d=(?P<Ring>[0-9]+)mm'    ## Get ring diameter in mm\n",
    "        r'.*?l=(?P<Tandem>[0-9]+)mm'  ## Get tandem length in mm\n",
    "        r'.*?(?P<Angle>[0-9]+)°'      ## Get angle in degrees\n",
    "        )\n",
    "    code_template = 'RT_A{Angle}R{Ring}L{Tandem}'\n",
    "    # Extract Applicator info from private tags in the DICOM header.\n",
    "    applicator_seq = dataset.get('ApplicationSetupSequence')\n",
    "    if not applicator_seq:\n",
    "        # Bail if Applicator sequence not found\n",
    "        return {}  \n",
    "    applicator_ds = applicator_seq[0]\n",
    "    appl_str = applicator_ds.get_item((0x300B, 0x1011)).value\n",
    "    if not appl_str:\n",
    "        # Bail if Applicator sting not found\n",
    "        return {}  \n",
    "    # Fix the formatting for the degree symbol and convert value to a string.\n",
    "    appl_str = appl_str.replace(b'\\xb0', b'\\xc2\\xb0').decode()\n",
    "    # extract Angle, ring diameter, and tandem length from Applicator name.\n",
    "    appl_param = appl_ptrn.match(appl_str).groupdict()\n",
    "    if appl_param is None:\n",
    "        # Return the raw applicator string if the format was not recognized.\n",
    "        return {'Applicator': appl_str}\n",
    "    # Make the code string\n",
    "    appl_code = code_template.format(**appl_param)\n",
    "    appl_param['Applicator'] = appl_code\n",
    "    return appl_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apl_info(dicom_ref: pd.DataFrame)-> pd.DataFrame:\n",
    "    '''Get the applicator info for each fraction.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table of applicator info with 'PatientID' and 'StudyDate'\n",
    "            ad Index\n",
    "    '''\n",
    "    plan_files = dicom_ref.Modality.str.contains('RTPLAN')\n",
    "    apl_ref = dicom_ref.loc[plan_files, ['PatientID', 'StudyDate', 'FilePath']]\n",
    "    apl_ref.set_index('FilePath', inplace=True)\n",
    "\n",
    "    apl_list = []\n",
    "    for file in apl_ref.index:\n",
    "        dataset = pydicom.dcmread(file)\n",
    "        apl_data = build_appl_code(dataset)\n",
    "        apl_data['PatientID'] = apl_ref.at[file, 'PatientID']\n",
    "        apl_data['StudyDate'] = apl_ref.at[file, 'StudyDate']\n",
    "        apl_list.append(apl_data)\n",
    "    apl_info = pd.DataFrame(apl_list)\n",
    "    apl_info.drop_duplicates(inplace=True)\n",
    "    apl_info.set_index(['PatientID', 'StudyDate'], inplace=True)\n",
    "    apl_info.dropna(inplace=True)    \n",
    "    return apl_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "As part of second-round data cleaning, need to make the following changes to \n",
    "the DICOM header:\n",
    "- Replace with fixed Values:\n",
    "> - `(0008,1048)\tPhysicians Of Record`\n",
    "> - `(0008,1070)\tOperators Name`\n",
    "> - Date of birth\n",
    "\n",
    "- Change tag from *BU0-045-KC8460_1* to *Oncentra* or *Eclipse*\n",
    "> `(0002,0016)\tSource Application Entity Title`\n",
    "> \n",
    "- Change other dates to date relative to earliest date (which is set to 2000-01-01)\n",
    "- Find these dates using the date value type\n",
    "> \n",
    "\n",
    "After changes are made, \n",
    "Save to revised directory structure:\n",
    "\tApplicator → Patient → Date → Modality → Source → Series ID (or other relevant label)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass through data to collect aggregate information.\n",
    "**Information Required:**\n",
    "| Information           | Obtained from                      |\n",
    "|-----------------------|------------------------------------|\n",
    "| Data Source           | Eclipse or Oncentra in file path   |\n",
    "| Earliest Patient Date | Study Dates                        |\n",
    "| Practice plans        | Study Dates with no image sets     |\n",
    "| Fraction Date         | Study Dates with plans             |\n",
    "| Total Fractions       | Count of fraction dates            |\n",
    "| Fraction Number       | Cumulative Count of fraction dates |\n",
    "| Applicator Code       | RT plan with same study date       |\n",
    "| MRI Images            | Is MR Modality in Study Date       |\n",
    "| No applicator Images  | Study Date with no plan            |\n",
    "| Number Of Slices      | Count of image files by series UID |\n",
    "| Notes                 | Custom csv file with links         |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Source *Eclipse* or *Oncentra*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(dicom_ref: pd.DataFrame)->pd.DataFrame:\n",
    "    '''Determine file source from path.\n",
    "\n",
    "    Adds a column containing 'Eclipse' or 'Oncentra' depending on where the \n",
    "    DICOM file originated.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The supplied table with a new column 'Source'.\n",
    "    '''\n",
    "    eclipse_files = dicom_ref.Folder.str.contains('Eclipse')\n",
    "    dicom_ref['Source'] = 'Oncentra'\n",
    "    dicom_ref.loc[eclipse_files, 'Source'] = 'Eclipse'\n",
    "    return dicom_ref"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_ref(file: Path)->Dict[str, str]:\n",
    "    '''Extract key data from the DICOm header\n",
    "\n",
    "    The following information is extracted:\n",
    "        'FilePath': DICOM file Path,\n",
    "        'Folder': String path that DICOM file is in.,\n",
    "        'FileName': The name of the DICOM file,\n",
    "        'PatientID': Patient ID\n",
    "        'Modality': Image or RT-DICOM modality,\n",
    "        'StudyDate': Date study that the file is associated with,\n",
    "        'Study_UID': Study Instance UID,\n",
    "        'Series_UID': Series Instance UID,\n",
    "        'Object_UID': Object Instance UID,\n",
    "        'FrameOfReferenceUID': Frame Of Reference UID,\n",
    "        'SeriesDescription': Series Description text,\n",
    "        'SeriesNumber': Series number within Study\n",
    "    Args:\n",
    "        file (Path): Path to the DICOM file\n",
    "    Returns:\n",
    "        Dict[str, str]: Dictionary containing key information about the file.\n",
    "    '''\n",
    "    dataset = pydicom.dcmread(file)\n",
    "    file_ref = {\n",
    "        'FilePath': file,\n",
    "        'Folder': str(file.parent),\n",
    "        'FileName': file.name,\n",
    "        'PatientID': dataset.get('PatientID'),\n",
    "        'Modality': dataset.get('Modality'),\n",
    "        'StudyDate': dataset.get('StudyDate'),\n",
    "        'Study_UID': dataset.get('StudyInstanceUID'),\n",
    "        'Series_UID': dataset.get('SeriesInstanceUID'),\n",
    "        'Object_UID': dataset.get('SOPInstanceUID'),\n",
    "        'FrameOfReferenceUID': dataset.get('FrameOfReferenceUID'),\n",
    "        'SeriesDescription': dataset.get('SeriesDescription'),\n",
    "        'SeriesNumber': dataset.get('SeriesNumber')\n",
    "        }\n",
    "    return file_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_scan(scan_dir: Path)->pd.DataFrame:\n",
    "    '''Get key information from collection of DICOM files.\n",
    "\n",
    "    For each DICOM file found, extract key information and create a table with \n",
    "    this information.\n",
    "\n",
    "    Args:\n",
    "        scan_dir (Path): Path to the folder containing DICOM files\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table of key information for all DICOM files in the folder.\n",
    "    '''\n",
    "    file_list = []\n",
    "    for file in scan_dir.glob('**/*.dcm'):\n",
    "        file_ref = get_file_ref(file)\n",
    "        file_list.append(file_ref)\n",
    "    dicom_ref = pd.DataFrame(file_list)\n",
    "    dicom_ref = get_source(dicom_ref)\n",
    "    return dicom_ref"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate info functions\n",
    "The following functions are used to generate aggregate information based on the \n",
    "initial information extracted from the DICOM files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of slices per image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_slices(dicom_ref: pd.DataFrame)->pd.Series:\n",
    "    '''Count number of image slices for each series.\n",
    "\n",
    "    Counts files for each Series UID\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Number of image files by Series UID\n",
    "    '''\n",
    "    image_modalities = ['MR', 'CT', 'PT']\n",
    "    image_file = dicom_ref.Modality.isin(image_modalities)\n",
    "\n",
    "    slice_cnt = dicom_ref.loc[image_file, :].groupby('Series_UID').count().Folder\n",
    "    slice_cnt.name = 'NumOfSlices'\n",
    "    return slice_cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the earliest date to use for date offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_offset(dicom_ref: pd.DataFrame)->pd.Series:\n",
    "    '''Find the earliest Study Date for each patient.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Earliest Study Date for each patient.\n",
    "    '''\n",
    "    date_offset = dicom_ref.groupby('PatientID').StudyDate.min()\n",
    "    date_offset.name = 'DateOffset'\n",
    "    date_offset = date_offset.apply(to_date)\n",
    "    return date_offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Modalities\n",
    "For each patient and date, count the number of files for each different modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_modalities(dicom_ref: pd.DataFrame)-> pd.DataFrame:\n",
    "    '''Build table of number of files for each different modality by date.\n",
    "\n",
    "    Date is used to distinguish between fractions and between treatment and \n",
    "    non-treatment dates.  We only care about image and plan counts so other \n",
    "    modalities are dropped. \n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table of number of files by modality and date.\n",
    "    '''\n",
    "    # Count files sub-grouped by patient, study date, and modality\n",
    "    mod_grp = ['PatientID', 'StudyDate', 'Modality']\n",
    "    # Do not need to count registration,structure set or DRR files\n",
    "    drop_cols = ['REG', 'RTIMAGE', 'RTSTRUCT', 'RTDOSE']\n",
    "    \n",
    "    # Count my modality for each date. Select one column to get a Series\n",
    "    mod_cnt = dicom_ref.groupby(mod_grp).count().Folder\n",
    "    # Create a table of date vs number of files for each modality\n",
    "    mod_cnt = mod_cnt.unstack('Modality')\n",
    "    # Remove columns for modalities we don't care about counting\n",
    "    mod_cnt.drop(columns=drop_cols, inplace=True)\n",
    "    return mod_cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify study dates where only *RTPLAN* modalities occur.\n",
    "These will need to be discarded because they are practice or QA plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_plans(mod_cnt: pd.DataFrame)-> pd.Series:\n",
    "    '''Identify study dates where only RTPLAN modalities occur.\n",
    "    \n",
    "    These will need to be discarded because they are practice or QA plans.\n",
    "    \n",
    "    Args:\n",
    "        mod_cnt (pd.DataFrame): Table of number of files by modality and date.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Boolean series by PatientId and Study Date. True if \n",
    "            Study Date contains only RTPLAN modalities.    \n",
    "    '''\n",
    "    img_cnt = mod_cnt.drop(columns='RTPLAN')\n",
    "    no_image = img_cnt.isna().all(axis='columns')\n",
    "    no_image.name = 'NoImages'\n",
    "    return no_image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fraction Number and Total Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fractions(mod_cnt: pd.DataFrame)->Tuple[pd.Series]:\n",
    "    '''Determine the fraction number total number of fractions for each patient.\n",
    "\n",
    "    Fractions are defined as Study Dates containing both an RTPLAN and CT \n",
    "    Modality files.\n",
    "\n",
    "    Args:\n",
    "        mod_cnt (pd.DataFrame): Table of number of files by modality and date.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.Series]: Total Fractions by patient, Fraction number by \n",
    "            PatientId and Study Date.\n",
    "    '''\n",
    "    has_plan = ~mod_cnt.RTPLAN.isna()\n",
    "    fraction_dates = mod_cnt.loc[has_plan, 'CT']\n",
    "    total_fractions = fraction_dates.groupby(level='PatientID').count()\n",
    "    total_fractions.name = 'TotalFractions'\n",
    "    \n",
    "    fraction_num = fraction_dates.groupby(level=['PatientID']).cumcount()\n",
    "    fraction_num = fraction_num + 1\n",
    "    fraction_num.name = 'FractionNum'\n",
    "    return total_fractions, fraction_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for MR image sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_with_mr(mod_cnt: pd.DataFrame)->pd.Series:\n",
    "    '''Identify Study Dates that contain MR imaging.\n",
    "\n",
    "    Args:\n",
    "        mod_cnt (pd.DataFrame): Table of number of files by modality and date.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Boolean series by PatientId and Study Date. True if \n",
    "            Study Date contains an MR image set.\n",
    "    '''\n",
    "    has_mr = ~mod_cnt.MR.isna()\n",
    "    has_mr.name = 'HasMR'\n",
    "    return has_mr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for patients with image sets where applicator is not present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_wo_applicator(mod_cnt: pd.DataFrame)->pd.Series:\n",
    "    '''Identify patients that have image sets without applicators.\n",
    "\n",
    "    Args:\n",
    "        mod_cnt (pd.DataFrame): Table of number of files by modality and date.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Boolean series by PatientId. True if patient has image sets \n",
    "            without applicators.\n",
    "    '''\n",
    "    has_plan = ~mod_cnt.RTPLAN.isna()\n",
    "    non_rx_dates = mod_cnt.loc[~has_plan, 'CT']\n",
    "    has_non_apl_img = non_rx_dates.groupby(level='PatientID').count() > 0\n",
    "    has_non_apl_img.name = 'HasReferenceImages'\n",
    "    return has_non_apl_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create revised directory structure:\n",
    "The file folder system has the following hierarchy:\n",
    "> Patient → Applicator → Date → Modality → Source → Series Description\n",
    "\n",
    "If the Series Description create an alternative label from the series \n",
    "number in the format: \n",
    "> Series Number *##*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_label(dicom_ref: pd.DataFrame)->pd.Series:\n",
    "    '''Create a series label\n",
    "\n",
    "    By default the label is the Series Description.  If the Series Description\n",
    "    is missing, create a label from the series number in the format: \n",
    "        `Series Number ##`\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Series label from Series Description or Series Number.\n",
    "    '''\n",
    "    def series_num_string(num):\n",
    "        num_s = str(num)\n",
    "        return f'Series Number {num_s}'\n",
    "\n",
    "    series_num = dicom_ref.SeriesNumber.apply(series_num_string)\n",
    "\n",
    "    series_label = dicom_ref.SeriesDescription\n",
    "    series_label.where(~series_label.isna(), series_num, inplace=True)\n",
    "    return series_label\n",
    "\n",
    "\n",
    "def build_path(dicom_ref: pd.DataFrame, new_dir: Path)->pd.Series:    \n",
    "    '''Create a new file path for saving the modifies file.\n",
    "\n",
    "    The file folder system has the following hierarchy:\n",
    "\t    PatientId → \n",
    "            ApplicatorCode → \n",
    "                SeriesDate → \n",
    "                    Modality → \n",
    "                        Source → \n",
    "                            SeriesDescription\n",
    "    If the Series Description create an alternative label from the series \n",
    "    number in the format: `Series Number ##`\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data for all DICOM files.\n",
    "        new_dir (Path): Top level directory to store modified DICOM files in.\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: New save path for the DICOM file.\n",
    "    '''    \n",
    "    dicom_ref['SeriesLabel'] = build_label(dicom_ref)\n",
    "    path_cols = ['Applicator', 'StudyDate', 'Modality', \n",
    "                'Source', 'SeriesLabel', 'FileName']\n",
    "    path_parts = dicom_ref[path_cols]\n",
    "\n",
    "    sub_path = dicom_ref.PatientID.str.cat(path_parts, sep='\\\\')\n",
    "    new_path = new_dir / sub_path \n",
    "    return new_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract aggregate information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reference_info(dicom_files: pd.DataFrame, \n",
    "                           new_dir: Path)->pd.DataFrame:\n",
    "    '''Get aggregate info from the initial reference data. \n",
    "    \n",
    "    At the patient level, information collected is:\n",
    "        The earliest Study date.\n",
    "        The total number of fractions.\n",
    "        Whether reference image sets without an applicator are present.\n",
    "        \n",
    "    At the Study Date level, information collected is:        \n",
    "        The fraction number.\n",
    "        The applicator used for the fraction.\n",
    "        Whether an MR image set is available for the given fraction.\n",
    "        Series to be discarded because they are for QA or practice planning.\n",
    "\n",
    "    At the Series level, information collected is:        \n",
    "        The number of slices in the series.\n",
    "        \n",
    "    Based on the aggregate info a new \"Save Path\" for each file is generated. \n",
    "\n",
    "    Args:\n",
    "        dicom_files (pd.DataFrame): Reference data for all DICOM files.\n",
    "        new_dir (Path): Top level directory to store modified DICOM files in.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Reference data for all DICOM files with additional \n",
    "        aggregate info added.\n",
    "    '''    \n",
    "    apl_info = get_apl_info(dicom_files)\n",
    "    date_offset = get_date_offset(dicom_files)\n",
    "    mod_cnt = count_modalities(dicom_files)\n",
    "    no_image = solo_plans(mod_cnt)\n",
    "    # Drop Series Dates where only RTPLAN modalities occur.\n",
    "    # These will need to be discarded because they are practice or QA plans.\n",
    "    mod_cnt = mod_cnt.loc[~no_image, :].copy()\n",
    "\n",
    "    total_fractions, fraction_num = count_fractions(mod_cnt)\n",
    "    has_mr = dates_with_mr(mod_cnt)\n",
    "    has_non_apl_img = dates_wo_applicator(mod_cnt)\n",
    "\n",
    "    pt_lvl_info = pd.concat([date_offset, total_fractions, has_non_apl_img], \n",
    "                            axis='columns')\n",
    "    pt_lvl_info.HasReferenceImages.fillna(False, inplace=True)\n",
    "    dicom_ref = dicom_files.join(pt_lvl_info, on='PatientID')\n",
    "\n",
    "    dt_lvl_info = pd.concat([fraction_num, has_mr, apl_info, no_image], \n",
    "                            axis='columns')\n",
    "    dicom_ref = dicom_ref.join(dt_lvl_info, on=['PatientID', 'StudyDate'])\n",
    "\n",
    "    slice_cnt = count_slices(dicom_ref)\n",
    "    dicom_ref = dicom_ref.join(slice_cnt, on='Series_UID')\n",
    "\n",
    "    # Discard Series Dates where only RTPLAN modalities occur because they are \n",
    "    # practice or QA plans.\n",
    "    dicom_ref = dicom_ref.loc[~dicom_ref.NoImages, :].copy()\n",
    "\n",
    "    dicom_ref.Applicator.fillna('None', inplace=True)\n",
    "\n",
    "    dicom_ref['NewPath'] = build_path(dicom_ref, new_dir)\n",
    "    \n",
    "    return dicom_ref"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary cleaning\n",
    "Functions that use aggregate information as part of anonymizing the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dates\n",
    "> \n",
    "- Change other dates to date relative to earliest date (which is set to 2000-01-01)\n",
    "- Find these dates using the date value type `DA`.\n",
    "> - `(0008, 0012) Instance Creation Date              DA: '20230414'`\n",
    "> - `(0008, 0020) Study Date                          DA: '20220906'`\n",
    "> - `(0008, 0021) Series Date                         DA: '20220906'`\n",
    "> - `(0008, 0022) Acquisition Date                    DA: '20220906'`\n",
    "> - `(0008, 0023) Content Date                        DA: '20220906'`\n",
    "> - `(0010, 0030) Patient's Birth Date                DA: '19570514'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_mod(dataset: pydicom.Dataset, data_element: pydicom.DataElement, \n",
    "             date_offset: date, ref_date=date(2000, 1, 1), \n",
    "             birth_date=date(1900, 1, 1)):\n",
    "    '''A pydicom callback function root that anonymizes dates.\n",
    "\n",
    "    If data_element is 'PatientBirthDate' change the value to birth_date.\n",
    "    \n",
    "    If data_element is any other date, shift the date by an offset from \n",
    "    ref_date that matches the different between the data_element date and \n",
    "    date_offset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pydicom.Dataset): The DICOM dataset to be modified\n",
    "        data_element (pydicom.): The DICOM element to be modified\n",
    "        date_offset (date): The original reference date to compare found \n",
    "            dates with.\n",
    "        ref_date (date, optional): The reference date to calculate the new date \n",
    "            offset from. Defaults to date(2000, 1, 1).\n",
    "        birth_date (date, optional): The date to use as a replacement for \n",
    "            'PatientBirthDate'. Defaults to date(1900, 1, 1).\n",
    "    '''\n",
    "    if data_element.VR == 'DA':\n",
    "        if data_element.tag == 'PatientBirthDate':\n",
    "            data_element.value = from_date(birth_date)\n",
    "        else:\n",
    "            new_date = date_shift(data_element.value, date_offset, ref_date)\n",
    "            data_element.value = new_date\n",
    "\n",
    "\n",
    "def anonymize_dates(dataset: pydicom.Dataset, date_offset: date, \n",
    "                    ref_date=date(2000, 1, 1), \n",
    "                    birth_date=date(1900, 1, 1))->pydicom.Dataset:\n",
    "    '''Anonymize all dates in the dataset while maintaining the same relative \n",
    "    dates.\n",
    "    \n",
    "    The 'PatientBirthDate' element is changed to birth_date.\n",
    "    \n",
    "    All other dates are shifted so that they maintain the same relative time \n",
    "    difference.  The dates found are compared with date_offset and then set to \n",
    "    a new date that has the same relative time difference with ref_date as the \n",
    "    original date had with date_offset.\n",
    "\n",
    "    Args:\n",
    "        dataset (pydicom.Dataset): The DICOM dataset to be modified.\n",
    "        date_offset (date): The original reference date to compare found \n",
    "            dates with.\n",
    "        ref_date (date, optional): The reference date to calculate the new date \n",
    "            offset from. Defaults to date(2000, 1, 1).\n",
    "        birth_date (date, optional): The date to use as a replacement for \n",
    "            'PatientBirthDate'. Defaults to date(1900, 1, 1).\n",
    "            \n",
    "    Returns:\n",
    "        pydicom.Dataset: The supplied DICOM dataset with modified dates.\n",
    "    '''\n",
    "    date_shifter_callback = partial(date_mod, date_offset=date_offset,\n",
    "                                    ref_date=ref_date, birth_date=birth_date)\n",
    "    dataset.walk(date_shifter_callback)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace staff names with blank strings:\n",
    "> - `(0008,1048)\tPhysicians Of Record`\n",
    "> - `(0008,1070)\tOperators Name`\n",
    "> - `(0008,0090)\tReferring Physician Name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_names(dataset: pydicom.Dataset)-> pydicom.Dataset:\n",
    "    '''Anonymize all staff names in the dataset.\n",
    "    \n",
    "    Elements with the tag 'OperatorsName' or 'PhysiciansOfRecord have their \n",
    "    values are converted to empty strings.\n",
    "    Args:\n",
    "        dataset (pydicom.Dataset): The DICOM dataset to be modified.\n",
    "            \n",
    "    Returns:\n",
    "        pydicom.Dataset: The supplied DICOM dataset with name elements.\n",
    "    '''\n",
    "    def no_name_callback(dataset, data_element):\n",
    "        if data_element.tag in ['OperatorsName', \n",
    "                                'PhysiciansOfRecord',\n",
    "                                'ReferringPhysicianName']:\n",
    "            data_element.value = ''\n",
    "        \n",
    "    dataset.walk(no_name_callback)\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the Source information to a DICOM tag\n",
    "\n",
    "1. Locate the first item in 'Contributing Equipment Sequence', if it is present.\n",
    "2. Verify that the value of the 'Contribution Description' is 'Cleaned' \n",
    "3. Find the 'Station Name' element and replace its value with `Source`.\n",
    "\n",
    "\n",
    "```\n",
    "> (0018, A001) Contributing Equipment Sequence     1 item(s) ---- \n",
    ">     (0008, 0070) Manufacturer                        LO: 'PixelMed'\n",
    ">     (0008, 1010) Station Name                        SH: 'Oncentra'\n",
    ">     (0008, 1090) Manufacturer's Model Name           LO: 'DicomCleaner'\n",
    ">     (0018, 1020) Software Versions                   LO: 'Wed Dec 18 15:38:40 EST 2019'\n",
    ">     (0018, a002) Contribution DateTime               DT: '20230417122754.967-0400'\n",
    ">     (0018, a003) Contribution Description            ST: 'Cleaned'\n",
    ">     (0040, a170)  Purpose of Reference Code Sequence  1 item(s) ---- \n",
    ">        (0008, 0100) Code Value                          SH: '109104'\n",
    ">        (0008, 0102) Coding Scheme Designator            SH: 'DCM'\n",
    ">        (0008, 0104) Code Meaning                        LO: 'De-identifying Equipment'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consider switching to**\n",
    "`(0002,0016)\tSource Application Entity Title\tBU0-045-KC8460_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source(dataset: pydicom.Dataset, source: str)-> pydicom.Dataset:\n",
    "    '''Add the data source name to the dataset.\n",
    "\n",
    "   Replaces the 'StationName' value in the first 'ContributingEquipmentSequence' \n",
    "   item with source.\n",
    "\n",
    "    Args:\n",
    "        dataset (pydicom.Dataset): The DICOM dataset to be modified.\n",
    "        source (str): The DICOM file data source 'Eclipse or 'Oncentra'.\n",
    "\n",
    "    Returns:\n",
    "        pydicom.Dataset: The supplied DICOM dataset with source added.\n",
    "    '''\n",
    "    sequence_tag = 'ContributingEquipmentSequence'\n",
    "    description_tag = 'ContributionDescription'\n",
    "    expected_description = 'Cleaned'\n",
    "    source_tag ='StationName'\n",
    "\n",
    "    if sequence_tag in dataset:\n",
    "        ds = dataset.data_element(sequence_tag)[0]\n",
    "        purpose = ds.get(description_tag)\n",
    "        if purpose == expected_description:\n",
    "            station = ds.data_element(source_tag)\n",
    "            station.value = source\n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Modifications and save modified files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_mod(dicom_ref: pd.DataFrame, ref_date=date(2000, 1, 1), \n",
    "              birth_date=date(1900, 1, 1)):\n",
    "    '''perform secondary anonymization of the DICOM files using aggregated \n",
    "    reference data.\n",
    "\n",
    "    Change patient date of birth to birth_date.\n",
    "    Convert other dates to a new date relative to earliest date.\n",
    "    Replace staff names with blank strings.\n",
    "    Add the data source name to the dataset.\n",
    "    Save the modified files.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data, including aggregate info for \n",
    "            all DICOM files.\n",
    "        ref_date (date, optional): The reference date to calculate the new date \n",
    "            offset from. Defaults to date(2000, 1, 1).\n",
    "        birth_date (date, optional): The date to use as a replacement for \n",
    "            'PatientBirthDate'. Defaults to date(1900, 1, 1).\n",
    "    '''       \n",
    "    def save_dicom_file(dataset: pydicom.Dataset, save_path: Path):\n",
    "        '''Save the modified DICOM file.\n",
    "        Args:\n",
    "            dataset (pydicom.Dataset): Modified DICOM file contents.\n",
    "            save_path (Path): Full path to save the modified file.\n",
    "        '''\n",
    "        folder = save_path.parent\n",
    "        if not folder.exists():\n",
    "            folder.mkdir(parents=True)\n",
    "        dataset.save_as(save_path)   \n",
    "\n",
    "        \n",
    "    for row in dicom_ref.itertuples(index=False):\n",
    "        dataset = pydicom.dcmread(row.FilePath)\n",
    "        earliest_date = row.DateOffset\n",
    "        source = row.Source\n",
    "        new_file_path = row.NewPath\n",
    "        dataset = anonymize_dates(dataset, earliest_date, ref_date=ref_date, \n",
    "                                birth_date=birth_date)\n",
    "        dataset = anonymize_names(dataset)\n",
    "        dataset = add_source(dataset, source)\n",
    "        \n",
    "        save_dicom_file(dataset, new_file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Set Lookup\n",
    "*Create a table of Structure sets to be linked to image sets.*\n",
    "\n",
    "Table contents:\n",
    "|Column Name        |Description                                           |\n",
    "|-------------------|------------------------------------------------------|\n",
    "|FilePath           |Full path to the Structure Set DICOM file             |\n",
    "|RelativePath       |Relative path string to be used by the Image Set table|\n",
    "|SeriesReference    |Series index in the form: StudyId.SeriesNumber        |\n",
    "|StructureSetID     |Label for the Structure Set                           |\n",
    "|FrameOfReferenceUID|Frame Of Reference UID for the Structure Set          |\n",
    "|ReferencedImageSet |Series UID for the associated image set               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_structure_set_lookup(dicom_ref: pd.DataFrame, \n",
    "                               top_dir: Path)->pd.DataFrame:\n",
    "    '''Create a table of Structure sets to be linked to image sets.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data, including aggregate info for \n",
    "            all DICOM files.\n",
    "        top_dir (Path): The path to a top level folder containing DICOM files.\n",
    "    '''\n",
    "    struct_set_mask = dicom_ref.Modality.isin(['RTSTRUCT'])\n",
    "    struct_set_ref = dicom_ref.loc[struct_set_mask, :]\n",
    "    structure_set_list = []\n",
    "    for row in struct_set_ref.itertuples(index=False):\n",
    "        structure_file = row.NewPath\n",
    "        relative_path = make_relative_path(structure_file, top_dir)\n",
    "        dataset = pydicom.dcmread(structure_file)\n",
    "        structure_set_ref = '.'.join([\n",
    "            str(dataset.get('StudyID','')), \n",
    "            str(dataset.get('SeriesNumber',''))\n",
    "            ])\n",
    "        structure_set_id = dataset.get('StructureSetLabel')\n",
    "        fr_ds = dataset.get('ReferencedFrameOfReferenceSequence')[0]\n",
    "        study_ref = fr_ds.get('RTReferencedStudySequence')[0]\n",
    "        series_ref = study_ref.get('RTReferencedSeriesSequence')[0]   \n",
    "        frame_of_reference_UID = fr_ds.get('FrameOfReferenceUID') \n",
    "        referenced_series_UID = series_ref.get('SeriesInstanceUID')\n",
    "        structure_set_dict = {\n",
    "            'FilePath': structure_file,\n",
    "            'RelativePath': relative_path,\n",
    "            'SeriesIndex': structure_set_ref,\n",
    "            'StructureSetID': structure_set_id,\n",
    "            'FrameOfReferenceUID': frame_of_reference_UID,\n",
    "            'ReferencedImageSet': referenced_series_UID,\n",
    "            'Source': row.Source\n",
    "            }\n",
    "        structure_set_list.append(structure_set_dict)\n",
    "\n",
    "    structure_set_lookup = pd.DataFrame(structure_set_list)\n",
    "    structure_set_lookup.sort_values(['ReferencedImageSet', 'Source'], \n",
    "                                     inplace=True)    \n",
    "    structure_set_lookup.set_index(['ReferencedImageSet', 'Source'], \n",
    "                                   inplace=True)\n",
    "    return structure_set_lookup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Set Table\n",
    "| Column               |      Description                    |Example|\n",
    "|----------------------|-------------------------------------|-------|\n",
    "| SeriesIndex          | StudyID.SeriesID                    |38805.2|\n",
    "| Modality             | Image modality CT or MR             |CT|\n",
    "| Applicator           | Applicator code with type & size    |A60R34L40|\n",
    "| PatientID            | CCSEO + Patient Code                |CCSEO005|\n",
    "| Source               | Exported from Eclipse or Oncentra   |Eclipse|\n",
    "| Notes                | Special info (to be added manually) |Prosthesis|\n",
    "| SeriesDescription    | Free text label                     |SAG T2 HIRES|\n",
    "| Slices               | Number of image slices              |304|\n",
    "| SliceThickness       | Slice Thickness in mm               |2|\n",
    "| ImageResolution      | Image Resolution in mm              |1.2|\n",
    "| StructureSet         | Matching Structure Set label        |HDR FR3|\n",
    "| StructureSetFile| Relative path to Structure Set Files|.\\CCSEO003\\ ... \\####.dcm|\n",
    "|StructureSetIndex     | SeriesIndex for Matching Structure Set|38040.21|\n",
    "|Study_UID             | Image Set Study UID|1.2.840.113704.1.111.7264.16182.10|\n",
    "|Series_UID            | Image Set Series UID|1.2.840.113704.1.111.7264.1682.10|\n",
    "|FrameOfReferenceUID   | Image Set Frame of Reference UID|1.2.840.11.7264.12.10|\n",
    "|Folder            | Relative path to Image Set Files|.\\CCSEO003\\ ... \\####.dcm|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_structure_set_ref(structure_set_lookup: pd.DataFrame, series_uid: str, \n",
    "                          source: str)->Dict[str, str]:\n",
    "    '''Get Structure set references for a given image series.\n",
    "\n",
    "    Find matching Structure Set references for a given image series and source.\n",
    "    If more than one Structure Set reference is present, combine them as a comma \n",
    "    separated string.\n",
    "\n",
    "    Args:\n",
    "        structure_set_lookup (pd.DataFrame): Table of Structure sets to be \n",
    "            linked to image sets\n",
    "        series_uid (str): UID of the series. The first part of the \n",
    "            structure_set_lookup index.\n",
    "        source (str): Series export source: 'Eclipse' or 'Oncentra' The second \n",
    "            part of the structure_set_lookup index.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: _description_\n",
    "    '''\n",
    "    def multi_set_merge(same_ref_col):\n",
    "        return same_ref_col.str.cat(sep=', ')\n",
    "    columns_names = {\n",
    "        'StructureSetID': 'StructureSet',\n",
    "        'RelativePath': 'StructureSetFile',\n",
    "        'SeriesIndex': 'StructureSetIndex'\n",
    "    }\n",
    "    col_select = list(columns_names.keys())\n",
    "    structure_set_ref = structure_set_lookup.loc[(series_uid, source),\n",
    "                                                 col_select]\n",
    "    structure_set_ref.rename(columns=columns_names, inplace=True)\n",
    "    if structure_set_ref.shape[0] > 1:\n",
    "        merged_ref = structure_set_ref.apply(multi_set_merge)\n",
    "        merged_dict = merged_ref.to_dict()\n",
    "    else:\n",
    "        merged_dict = structure_set_ref.to_dict(orient='records')[0]\n",
    "    return merged_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_image_table(dicom_ref: pd.DataFrame, \n",
    "                      structure_set_lookup: pd.DataFrame, \n",
    "                      top_dir: Path)->pd.DataFrame:\n",
    "    '''Build a table describing all Image sets.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data, including aggregate info for \n",
    "            all DICOM files.\n",
    "        structure_set_lookup (pd.DataFrame): Table of Structure sets to be \n",
    "            linked to image sets\n",
    "        top_dir (Path): The path to a top level folder containing DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table describing all Image sets\n",
    "    '''\n",
    "    image_set_mask = dicom_ref.Modality.isin(['CT', 'MR'])\n",
    "    image_set_ref = dicom_ref.loc[image_set_mask, :]\n",
    "    image_list = []\n",
    "    for row in image_set_ref.itertuples(index=False):\n",
    "        image_file_path = row.NewPath\n",
    "        dataset = pydicom.dcmread(image_file_path)\n",
    "        # Build an index to the series in the form: StudyID.SeriesNumber\n",
    "        series_ref = '.'.join([\n",
    "            str(dataset.get('StudyID','')), \n",
    "            str(dataset.get('SeriesNumber',''))\n",
    "            ])\n",
    "        # Assuming the image is square, extract the resolution from one axis.\n",
    "        res = dataset.get('PixelSpacing')\n",
    "        if res:\n",
    "            img_resolution = res[0]\n",
    "        else:\n",
    "            img_resolution = np.nan\n",
    "        # Generate the relative path to the folder containing the image series.\n",
    "        image_folder = image_file_path.parent\n",
    "        relative_folder = make_relative_path(image_folder, top_dir)\n",
    "        # Get the Series UID and source to search for a matching structure set\n",
    "        series_uid = row.Series_UID\n",
    "        source = row.Source\n",
    "        # Begin building the table elements\n",
    "        image_dict = {\n",
    "            'SeriesIndex': series_ref,\n",
    "            'Modality': row.Modality,\n",
    "            'Applicator': row.Applicator,\n",
    "            'PatientID': row.PatientID,\n",
    "            'Source': source,\n",
    "            'SeriesDescription': row.SeriesDescription,\n",
    "            'Slices': row.NumOfSlices,\n",
    "            'SliceThickness': dataset.get('SliceThickness'),\n",
    "            'ImageResolution': img_resolution,\n",
    "            'Study_UID': row.Study_UID,\n",
    "            'Series_UID': row.Series_UID,\n",
    "            'FrameOfReferenceUID': row.FrameOfReferenceUID,\n",
    "            'Folder': relative_folder\n",
    "            }    \n",
    "        # Add Structure set information if it exists\n",
    "        if (series_uid, source) in structure_set_lookup.index:\n",
    "            structure_set_dict = add_structure_set_ref(structure_set_lookup, \n",
    "                                                       series_uid, source)\n",
    "            image_dict.update(structure_set_dict)\n",
    "        image_list.append(image_dict)\n",
    "    image_table = pd.DataFrame(image_list)\n",
    "    image_table.drop_duplicates(inplace=True)\n",
    "    image_table.set_index('SeriesIndex', inplace=True)\n",
    "    image_table.fillna('', inplace=True)\n",
    "    return image_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Set Table\n",
    "| Column               |      Description                    |Example   |\n",
    "|----------------------|-------------------------------------|----------|\n",
    "| Structure ID           | Get from Structure DICOM file             |\n",
    "| Structure Set ID     | Get from Structure DICOM file       |          |\n",
    "| Series Description   | Free text label                     |SAG T2 HIRES|\n",
    "| Image Modality       | Get from referenced series          |CT        |\n",
    "| Applicator           | Applicator code with type & size    |A60R34L40 |\n",
    "| Patient ID           | CCSEO + Patient Code                |CCSEO005  |\n",
    "| Source               | Exported from Eclipse or Oncentra   |Eclipse   |\n",
    "| Notes                | Special info (To be added manually) |Prosthesis|\n",
    "| Slices Contoured       | Get from Structure DICOM file             |\n",
    "| Structure Resolution   | If possible: Normal or High Res           |\n",
    "| Structure Label        | Get from Structure DICOM file             |\n",
    "| Code Scheme            | Get from Structure DICOM file             |\n",
    "| Code Scheme Version    | Get from Structure DICOM file             |\n",
    "| ROI Number             | Get from Structure DICOM file             |\n",
    "| Structure Set UID      | Get from DICOM file                       |\n",
    "| Image Series UID       | Get from DICOM file                       |\n",
    "| FrameOfReferenceUID   | Image Set Frame of Reference UID|1.2.840.11.7264.12.10|\n",
    "| StructureSetIndex     | SeriesIndex for Structure Set|38040.21|\n",
    "| StructureSetFile| Relative path to Structure Set File|.\\CCSEO003\\ ... \\####.dcm|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get contour information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_info(dataset: pydicom.Dataset)->pd.DataFrame:\n",
    "    def get_roi_number(dataset):\n",
    "        roi_list = []\n",
    "        roi_seq = dataset.get('StructureSetROISequence')\n",
    "        for roi in roi_seq:\n",
    "            roi_dict = {\n",
    "                'ROI_Number': roi.get('ROINumber'),\n",
    "                'Name': roi.get('ROIName')            \n",
    "            }\n",
    "            roi_list.append(roi_dict)\n",
    "        roi_num = pd.DataFrame(roi_list)\n",
    "        roi_num.set_index('ROI_Number', inplace=True)\n",
    "        return roi_num\n",
    "    \n",
    "    def get_roi_contours(dataset):\n",
    "        roi_contours = []\n",
    "        roi_seq = dataset.get('ROIContourSequence')\n",
    "        for roi in roi_seq:\n",
    "            roi_dict = {'ROI_Number': roi.get('ReferencedROINumber')}\n",
    "            slice_seq = roi.get('ContourSequence')\n",
    "            if slice_seq:\n",
    "                roi_dict['SlicesContoured'] = len(slice_seq)\n",
    "            else:\n",
    "                roi_dict['SlicesContoured'] = 0\n",
    "            roi_contours.append(roi_dict)\n",
    "        roi_count = pd.DataFrame(roi_contours)\n",
    "        roi_count.set_index('ROI_Number', inplace=True)\n",
    "        return roi_count\n",
    "    \n",
    "    def get_roi_ref(dataset):\n",
    "        roi_ref = []\n",
    "        roi_seq = dataset.get('RTROIObservationsSequence')\n",
    "        for roi in roi_seq:\n",
    "            roi_dict = {'ROI_Number': roi.get('ReferencedROINumber'),\n",
    "                        'ID': roi.get('ROIObservationLabel')}\n",
    "            roi_id_seq = roi.get('RTROIIdentificationCodeSequence')\n",
    "            if roi_id_seq:\n",
    "                roi_id = roi_id_seq[0]\n",
    "                roi_dict['StructureCode'] = roi_id.get('CodeValue')\n",
    "                roi_dict['StructureLabel'] = roi_id.get('CodeMeaning')\n",
    "                roi_dict['CodeScheme'] = roi_id.get('CodingSchemeDesignator')\n",
    "                roi_dict['CodeSchemeVersion'] = roi_id.get('CodingSchemeVersion')\n",
    "            roi_ref.append(roi_dict)\n",
    "        roi_id = pd.DataFrame(roi_ref)\n",
    "        roi_id.set_index('ROI_Number', inplace=True)\n",
    "        return roi_id\n",
    "    \n",
    "    struct_data = [\n",
    "        get_roi_number(dataset),\n",
    "        get_roi_contours(dataset),\n",
    "        get_roi_ref(dataset)\n",
    "        ]\n",
    "    contours = pd.concat(struct_data, axis='columns')\n",
    "    contours.reset_index(inplace=True)\n",
    "    contours['StructureSetUID'] = dataset.get('SOPInstanceUID')\n",
    "    contours.set_index('StructureSetUID', inplace=True)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_structure_files(structure_set_lookup, image_table):\n",
    "    image_lookup = image_table.set_index(['Series_UID', 'Source'], drop=False)\n",
    "    structure_set_info = structure_set_lookup.join(image_lookup, how='inner', \n",
    "                                                   rsuffix='Image')\n",
    "    structure_set_list = []\n",
    "    contours_list = []\n",
    "    for row in structure_set_info.itertuples(index=False):\n",
    "        dataset = pydicom.dcmread(row.FilePath)\n",
    "        structure_set_dict = {\n",
    "            'StructureSetID': row.StructureSetID,\n",
    "            'SeriesDescription': row.SeriesDescription,\n",
    "            'ImageModality': row.Modality,\n",
    "            'Applicator': row.Applicator,\n",
    "            'PatientID': row.PatientID,\n",
    "            'Source': row.Source,\n",
    "            'StructureSetUID': dataset.get('SOPInstanceUID'),\n",
    "            'ImageSeriesUID': row.Series_UID,\n",
    "            'FrameOfReferenceUID': row.FrameOfReferenceUID,\n",
    "            'StructureSetIndex': row.StructureSetIndex,\n",
    "            'StructureSetFile': row.StructureSetFile\n",
    "            }\n",
    "        structure_set_list.append(structure_set_dict)\n",
    "        contours_list.append(get_contour_info(dataset))\n",
    "    contour_info = pd.concat(contours_list, axis='rows')\n",
    "    structure_set_table = pd.DataFrame(structure_set_list)\n",
    "    structure_set_table.set_index('StructureSetUID', drop=False, inplace=True)\n",
    "    contour_table = contour_info.join(structure_set_table)\n",
    "    row_selection = contour_table.SlicesContoured > 0\n",
    "    column_order = [\n",
    "        'StructureID',\n",
    "        'StructureSetID',\n",
    "        'SeriesDescription',\n",
    "        'ImageModality',\n",
    "        'Applicator',\n",
    "        'PatientID',\n",
    "        'Source',\n",
    "        'SlicesContoured',\n",
    "        'StructureResolution',\n",
    "        'StructureLabel',\n",
    "        'CodeScheme',\n",
    "        'CodeSchemeVersion',\n",
    "        'ROI_Number',\n",
    "        'StructureSetUID',\n",
    "        'ImageSeriesUID',\n",
    "        'FrameOfReferenceUID',\n",
    "        'StructureSetIndex',\n",
    "        'StructureSetFile'\n",
    "        ]   \n",
    "    column_selection = [column for column in column_order \n",
    "                       if column in contour_table.columns]\n",
    "    contour_table = contour_table.loc[row_selection, column_selection]\n",
    "    contour_table.drop_duplicates(inplace=True)\n",
    "    return contour_table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registrations Table\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-vwm9{background-color:#329a9d;color:#000000;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-da89{background-color:#96fffb;color:#000000;text-align:left;vertical-align:middle}\n",
    ".tg .tg-5szv{background-color:#e2efda;color:#000000;font-family:Arial, Helvetica, sans-serif !important;text-align:left;\n",
    "  vertical-align:middle}\n",
    ".tg .tg-00be{background-color:#5b9bd5;color:#000000;font-family:Arial, Helvetica, sans-serif !important;font-weight:bold;\n",
    "  text-align:center;vertical-align:middle}\n",
    ".tg .tg-uivm{background-color:#ddebf7;color:#000000;font-family:Arial, Helvetica, sans-serif !important;text-align:left;\n",
    "  vertical-align:middle}\n",
    ".tg .tg-p9fm{background-color:#70ad47;color:#000000;font-family:Arial, Helvetica, sans-serif !important;font-weight:bold;\n",
    "  text-align:center;vertical-align:middle}\n",
    ".tg .tg-ndfp{background-color:#e2efda;color:#000000;text-align:left;vertical-align:middle}\n",
    ".tg .tg-a350{background-color:#ffc000;color:#000000;font-weight:bold;text-align:center;vertical-align:middle}\n",
    ".tg .tg-xzj8{background-color:#fff2cc;color:#000000;text-align:left;vertical-align:middle}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-00be\" rowspan=\"3\">Index Info</th>\n",
    "    <th class=\"tg-uivm\">SeriesIndex</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-uivm\">PatientID</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-uivm\">File</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-p9fm\" rowspan=\"3\">Registration Info</td>\n",
    "    <td class=\"tg-5szv\">Type</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ndfp\">Method</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-ndfp\">Matrix</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-a350\" rowspan=\"5\">From</td>\n",
    "    <td class=\"tg-xzj8\">Modality</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-xzj8\">Applicator</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-xzj8\">SeriesIndex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-xzj8\">Series_UID</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-xzj8\">FrameOfReference_UID</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-vwm9\" rowspan=\"5\">To</td>\n",
    "    <td class=\"tg-da89\">Modality</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-da89\">Applicator</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-da89\">SeriesIndex</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-da89\">Series_UID</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-da89\">FrameOfReference_UID</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_referenced_series(reg_dataset: pydicom.Dataset)->Dict[str, str]:\n",
    "    '''Extract the Image Series UIDs for the image registration\n",
    "\n",
    "    Takes a DICOM Registration dataset and returns a dictionary with the \n",
    "    following two items:\n",
    "        RegistrationFromSeries_UID\n",
    "        RegistrationToSeries_UID\n",
    "\n",
    "    Args:\n",
    "        reg_dataset (pydicom.Dataset): A DICOM Registration dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary with the 'From' and 'To' Image Set \n",
    "            Series UIDs.\n",
    "    '''\n",
    "    from_ref_series_seq = reg_dataset.get('ReferencedSeriesSequence')\n",
    "    to_study_seq = reg_dataset.get('StudiesContainingOtherReferencedInstancesSequence')\n",
    "    to_ref_series_seq = to_study_seq[0].get('ReferencedSeriesSequence')\n",
    "    referenced_series = {\n",
    "        'RegistrationFromSeries_UID': from_ref_series_seq[0].get('SeriesInstanceUID'),\n",
    "        'RegistrationToSeries_UID': to_ref_series_seq[0].get('SeriesInstanceUID')\n",
    "        }\n",
    "    return referenced_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_registration_info(reg_dataset: pydicom.Dataset)->Dict[str, str]:\n",
    "    '''Extract details of an image registration.\n",
    "\n",
    "    Takes a DICOM Registration dataset and returns a dictionary with the \n",
    "    following information:\n",
    "        - 'From' and 'To' Frame Of Reference UIDs\n",
    "        - Type of registration e.g. 'RIGID'\n",
    "        - Registration method e.g. 'Visual Alignment'\n",
    "        - String representation of the Registration Matrix\n",
    "\n",
    "    Args:\n",
    "        reg_dataset (pydicom.Dataset): A DICOM Registration dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing registration details.\n",
    "    '''\n",
    "    reg_seq = reg_dataset.get('RegistrationSequence')\n",
    "    matrix_reg_seq = reg_seq[1].get('MatrixRegistrationSequence')\n",
    "    matrix_seq = matrix_reg_seq[0].get('MatrixSequence')\n",
    "    matrix_reg_code_seq = matrix_reg_seq[0].get('RegistrationTypeCodeSequence')       \n",
    "    reg_matrix = matrix_seq[0].get('FrameOfReferenceTransformationMatrix')\n",
    "    reg_matrix_str =  list_to_str(reg_matrix) \n",
    "    registration_info = {\n",
    "        'FromFrameOfReference_UID': reg_seq[0].get('FrameOfReferenceUID'),\n",
    "        'ToFrameOfReference_UID': reg_seq[1].get('FrameOfReferenceUID'),\n",
    "        'RegistrationType': matrix_seq[0].get('FrameOfReferenceTransformationMatrixType'),\n",
    "        'RegistrationMethod': matrix_reg_code_seq[0].get('CodeMeaning'),\n",
    "        'RegistrationMatrix': reg_matrix_str\n",
    "        }\n",
    "    return registration_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_set_lookup(image_table: pd.DataFrame)->pd.DataFrame:\n",
    "    '''Convert the image table into one that can be searched by Series UID.\n",
    "    \n",
    "    Note: Eclipse and Oncentra use the same Image Set Series UID, but this table \n",
    "    only references the Eclipse image sets.\n",
    "\n",
    "    Args:\n",
    "        image_table (pd.DataFrame): Table describing all Image sets\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table describing all unique image sets, indexed on \n",
    "            Series UID.\n",
    "    '''\n",
    "    image_set_lookup = image_table.reset_index()\n",
    "    image_set_lookup.sort_values(['Series_UID', 'Source'])\n",
    "    image_set_lookup.drop_duplicates('Series_UID', inplace=True)\n",
    "    image_set_lookup.set_index('Series_UID', inplace=True)\n",
    "    return image_set_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_ref(referenced_series: Dict[str, str], \n",
    "                  image_set_lookup: pd.DataFrame)->Dict[str, str]:\n",
    "       '''Get Image Set reference info for an image registration.\n",
    "\n",
    "       Returns Modality, Applicator, SeriesIndex and StructureSetIndex for \n",
    "       'From' and 'To' Image Sets\n",
    "\n",
    "       Args:\n",
    "           referenced_series (Dict[str, str]): A dictionary with the following \n",
    "            two items:\n",
    "                RegistrationFromSeries_UID\n",
    "                RegistrationToSeries_UID\n",
    "           image_set_lookup (pd.DataFrame): Table describing all unique image \n",
    "            sets, indexed on \n",
    "            Series UID.\n",
    "       Returns:\n",
    "           Dict[str, str]: A dictionary with Modality, Applicator, SeriesIndex \n",
    "            and StructureSetIndex info for 'From' and 'To' Image Sets.       \n",
    "       '''\n",
    "       from_series_uid = referenced_series['RegistrationFromSeries_UID']\n",
    "       from_series = image_set_lookup.loc[from_series_uid,:]\n",
    "       \n",
    "       to_series_uid = referenced_series['RegistrationToSeries_UID']\n",
    "       to_series = image_set_lookup.loc[to_series_uid,:]\n",
    "       \n",
    "       series_info = {\n",
    "              'FromModality': from_series.Modality,\n",
    "              'ToModality': to_series.Modality,\n",
    "              'FromApplicator': from_series.Applicator,\n",
    "              'ToApplicator': to_series.Applicator,              \n",
    "              'FromSeriesIndex': from_series.SeriesIndex,\n",
    "              'ToSeriesIndex': to_series.SeriesIndex,              \n",
    "              'FromStructureSetIndex': from_series.StructureSetIndex,\n",
    "              'ToStructureSetIndex': to_series.StructureSetIndex\n",
    "              }\n",
    "       return series_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reg_table(dicom_ref: pd.DataFrame, \n",
    "                      image_set_lookup: pd.DataFrame, \n",
    "                      top_dir: Path)->pd.DataFrame:\n",
    "    '''Build a table describing all Image sets.\n",
    "\n",
    "    Args:\n",
    "        dicom_ref (pd.DataFrame): Reference data, including aggregate info for \n",
    "            all DICOM files.\n",
    "        structure_set_lookup (pd.DataFrame): Table of Structure sets to be \n",
    "            linked to image sets\n",
    "        top_dir (Path): The path to a top level folder containing DICOM files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table describing all Image sets\n",
    "    '''\n",
    "    reg_mask = dicom_ref.Modality.isin(['REG'])\n",
    "    reg_ref = dicom_ref.loc[reg_mask, :]\n",
    "    \n",
    "    \n",
    "    reg_list = []\n",
    "    for row in reg_ref.itertuples(index=False):\n",
    "        reg_file_path = row.NewPath\n",
    "        dataset = pydicom.dcmread(reg_file_path)\n",
    "        # Build an index to the series in the form: StudyID.SeriesNumber\n",
    "        series_ref = '.'.join([\n",
    "            str(dataset.get('StudyID','')), \n",
    "            str(dataset.get('SeriesNumber',''))\n",
    "            ])\n",
    "        # Generate the relative path to the registration file.\n",
    "        relative_path = make_relative_path(reg_file_path, top_dir)\n",
    "        # Begin building the table elements\n",
    "        reg_dict = {\n",
    "            'SeriesIndex': series_ref,\n",
    "            'PatientID': row.PatientID,\n",
    "            'File': relative_path\n",
    "            }    \n",
    "        reg_info = get_registration_info(dataset)\n",
    "        reg_dict.update(reg_info)\n",
    "        referenced_series = get_referenced_series(dataset)\n",
    "        series_info = get_image_ref(referenced_series, image_set_lookup)\n",
    "        reg_dict.update(series_info)\n",
    "        reg_dict.update(referenced_series)\n",
    "        reg_list.append(reg_dict)\n",
    "    reg_table = pd.DataFrame(reg_list)\n",
    "    #image_table.drop_duplicates(inplace=True)\n",
    "    #image_table.set_index('SeriesIndex', inplace=True)\n",
    "    #image_table.fillna('', inplace=True)\n",
    "    return reg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information required for second cleaning\n",
    "dicom_files = initial_scan(working_dir)\n",
    "dicom_ref = extract_reference_info(dicom_files, cleaned_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform second cleaning and build new directory structure\n",
    "#dicom_mod(dicom_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the image set table and link images with structure sets\n",
    "structure_set_lookup = build_structure_set_lookup(dicom_ref, top_dir)\n",
    "image_table = build_image_table(dicom_ref, structure_set_lookup, top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the contours table\n",
    "contour_table = scan_structure_files(structure_set_lookup, image_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Image Registrations table\n",
    "image_set_lookup = make_image_set_lookup(image_table)\n",
    "reg_table = build_reg_table(dicom_ref, image_set_lookup, top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xw.Book()\n",
    "wb.save(save_file)\n",
    "\n",
    "dicom_ref_for_excel = dicom_ref.drop(columns=['NewPath', 'FilePath'])\n",
    "structure_set_lookup_for_excel = structure_set_lookup.drop(columns=['FilePath'])\n",
    "\n",
    "active_sheet = wb.sheets.add('Files')\n",
    "xw.view(dicom_ref_for_excel, sheet=active_sheet)\n",
    "\n",
    "active_sheet = wb.sheets.add('Structure Sets')\n",
    "xw.view(structure_set_lookup_for_excel, sheet=active_sheet)\n",
    "\n",
    "active_sheet = wb.sheets.add('Contours')\n",
    "xw.view(contour_table, sheet=active_sheet)\n",
    "\n",
    "active_sheet = wb.sheets.add('Registration Links')\n",
    "xw.view(reg_table, sheet=active_sheet)\n",
    "\n",
    "active_sheet = wb.sheets.add('Image Info')\n",
    "xw.view(image_table, sheet=active_sheet)\n",
    "\n",
    "wb.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VarianStandard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
